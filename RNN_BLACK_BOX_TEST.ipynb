{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "yGlDPXT2TEQg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNvr5dHXTfHf",
        "outputId": "7a62c770-b812-420d-b3c7-31cea111c63e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "import numpy\n",
        "\n",
        "target =  ['ht1', 'muff']\n",
        "data_dir = '/content/drive/My Drive/NMAL_project/RNN_BLACK_BOX_TEST/Data'\n",
        "target_dir = '/content/drive/My Drive/NMAL_project/RNN_BLACK_BOX_TEST/Data_proc'\n",
        "sub_dir = ['test', 'train', 'val']\n",
        "ext = ['input', 'target']\n",
        "\n",
        "for s in sub_dir:\n",
        "    for t in target:\n",
        "        for e in ext:\n",
        "            s_dir = os.path.join(data_dir, s, t)\n",
        "            t_dir = os.path.join(target_dir, s, t)\n",
        "            if(not os.path.exists(t_dir)):\n",
        "                os.makedirs(t_dir)\n",
        "                audio, sr = librosa.load(s_dir+'-'+e+'.wav')\n",
        "                seg_len = (int)(sr * 0.5)\n",
        "                for i in range(int(len(audio)/seg_len)):\n",
        "                    sf.write(os.path.join(t_dir, e)+str(i)+'.wav', numpy.array(audio[i*seg_len:(i+1)*seg_len]),sr)\n",
        "\n"
      ],
      "metadata": {
        "id": "qykd2os09FN0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "393ZoWG-S-yj"
      },
      "outputs": [],
      "source": [
        "class Audio(Dataset):\n",
        "    def __init__(self, data_dir, target):\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "        else:\n",
        "            self.device = 'cpu'\n",
        "        self.data_dir = data_dir\n",
        "        self.ext = ['input', 'target']\n",
        "        self.target = target\n",
        "        audio, self.sr = librosa.load(os.path.join(data_dir, 'ht1', 'input1.wav'))\n",
        "        self.len = 680\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index) -> list:\n",
        "\n",
        "        x_path = os.path.join(self.data_dir, self.target, self.ext[0]+str(index)+'.wav')\n",
        "        y_path = os.path.join(self.data_dir, self.target, self.ext[1]+str(index)+'.wav')\n",
        "        x, _ = librosa.load(x_path)\n",
        "        y, _ = librosa.load(y_path)\n",
        "\n",
        "        return torch.tensor(x), torch.tensor(y)\n",
        "\n",
        "    def show(self):\n",
        "        print(f'The audio length is {self.len*0.5} sec')\n",
        "        print(f'Total {self.len} datapoints')\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, num_layer, hidden_size, batch_size):\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "        else:\n",
        "            self.device = 'cpu'\n",
        "        self.batch_size = batch_size\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layer = num_layer\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layer, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        batch_size = x.size(0)\n",
        "        logic, (h, c)= self.rnn(x.unsqueeze(-1), (h, c))\n",
        "        out = self.fc(logic)\n",
        "        return out, (h, c)\n",
        "\n",
        "    def init_state(self):\n",
        "        return (torch.zeros(self.num_layer, self.batch_size, self.hidden_size, device=self.device),\n",
        "                 torch.zeros(self.num_layer, self.batch_size, self.hidden_size, device=self.device))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ESR(nn.Module):\n",
        "    def __init__(self, weight=None, pre_filt=[1.0, 0.85]):\n",
        "        super(ESR, self).__init__()\n",
        "        self.weight = weight\n",
        "        self.pre_filt = pre_filt\n",
        "    def forward(self, input, output):\n",
        "        if self.pre_filt is not None:\n",
        "            print(self.pre_filt)\n",
        "            output_p = torch.zeros(output.shape).to(device)\n",
        "            input_p = torch.zeros(input.shape).to(device)\n",
        "            for i in range(output.shape[1]):\n",
        "                for j, b in enumerate(self.pre_filt):\n",
        "                    output_p[:, i] = output_p[:, i]+output[:, i-j]*b\n",
        "                    input_p[:, i] = input_p[:, i]+input[:, i-j]*b\n",
        "\n",
        "            diff_p = output_p - input_p\n",
        "            esr_loss = torch.sum(diff_p**2, dim=1)/torch.sum(output_p**2, dim=1)\n",
        "        else:\n",
        "            diff = output-input\n",
        "            esr_loss = torch.sum(diff**2, dim=1)/torch.sum(output**2, dim=1)\n",
        "\n",
        "        diff = output-input\n",
        "        dc_loss = torch.sum(diff**2, dim=1)/torch.sum(output**2, dim=1)\n",
        "        loss = torch.sum(esr_loss + dc_loss)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "LFfSGjZE-qHx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/NMAL_project/RNN_BLACK_BOX_TEST/Data_proc/train'\n",
        "torch.cuda.empty_cache()\n",
        "train_input = Audio(data_dir, 'ht1')\n",
        "train_input.show()\n",
        "train_dataloader = DataLoader(train_input, batch_size=40, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(device)\n",
        "\n",
        "seq_len = int(train_input.sr * 0.5)\n",
        "model = RNN(input_size=1, hidden_size=12, num_layer=1, batch_size=40).to(device)\n",
        "\n",
        "num_epoch = 10\n",
        "learning_rate = 1e-4\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = ESR()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "dh8YC4-gTNL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a26158-6cab-45b0-f7aa-66c1151ddc48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The audio length is 340.0 sec\n",
            "Total 680 datapoints\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(True)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    (h, c) = model.init_state()\n",
        "    total_loss = 0.0\n",
        "    for x, y in tqdm(train_dataloader, desc=f'Epoch {epoch+1}', unit='batch'):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimiser.zero_grad()\n",
        "        out, (h, c) = model(x, h, c)\n",
        "        # print(out.size())\n",
        "        loss = loss_fn(out[:, :, 0], y)\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimiser.step()\n",
        "        total_loss = total_loss+loss\n",
        "\n",
        "    print(f'Total loss: {total_loss}')\n"
      ],
      "metadata": {
        "id": "nt0n1OPCxOKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34cbbf5-25cd-4ec3-d932-407e313fb355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   0%|          | 0/17 [00:00<?, ?batch/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/NMAL_project/RNN_BLACK_BOX_TEST/RNN_model_highpass_prefilt_CrossEntrophy_24.pth')"
      ],
      "metadata": {
        "id": "e7FLwTqHVh8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YuFAhjCqrdG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}